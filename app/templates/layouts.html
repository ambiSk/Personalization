<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hyper-Personalized 3D Avatars & Apparels From a Single Image</title>
    <link rel="icon" href="https://storage.googleapis.com/platform-qa-segments/micro-apps/hike-website/hikelogo.png" alt="ðŸ•¹ ðŸ‘¾ ðŸ’°" type="image/icon type">
    <link rel="stylesheet" href="{{url_for('static',_external = True, _scheme = 'https', filename = 'main.css')}}">

    <!-- BootStrap 5.2.0 Beta CSS only -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0-beta1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-0evHe/X+R7YkIZDRvuzKMRqM+OrBnVFBL6DOitfPri4tjfHxaWutUpFmBp4vmVor" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css"/>
</head>
<body>
    <div class="test">
        <h2> Hyper-Personalized 3D Avatars & Apparels From a Single Image</h2>
        <!--h5><a href="mailto:pankajd@hike.in">Pankaj Dahiya</a>, <a href="mailto:srishtigoel72@gmail.com">Srishti Goel</a>, <a href="mailto:pranshu.agarwal1996@gmail.com">Pranshu Agarwal</a>, <a href="mailto:omisha.s@hike.in">Omisha Sapra</a>, <a href="mailto:kush@hike.in">Kush Khurana</a>, <a href="mailto:ankur@hike.in">Ankur Narang</a>, <a href="mailto:neeraj2k14@gmail.com">Neeraj Kumar</a>, <a href="mailto:ambeshs@hike.in">Ambesh Shekhar</a>, <a href="mailto:mujtaba@hike.in">Mujtaba Hasan</a>, <a href="mailto:arpitrastogi0211@gmail.com">Arpit Rastogi</a>, <a href="mailto:vaibhavgupta2507@gmail.com">Vaibhav Gupta </a> and <a href="mailto:dipankars@hike.in">Dipankar Sarkar</a></h5-->
    </div>
    
    <img src="{{url_for('static',_external = True, _scheme = 'https', filename = '/teaser.png')}}" class = "teaser">

    <div class="abstract">
        <p>We present a 3D Avatar system which automates creation of a hyper-personalized avatar and apparels from a single image. The generated 3D Avatar and apparel is highly personalized and available at multiple resolutions to suit a variety of use-cases & devices. We personalize the avatar based on a single image of a user, by deforming a base facial mesh via 250 custom blend-shapes. We configure the hair, beard & various accessories by picking from thousands of possible combinations that align closely to match the user's taste, based on key themes that emerge from the image. Given an input image, hundreds of deformations and themes are inferred by a multi-task learner, which leverages facial landmark detection, geometric feature extraction, image classification and segmentation models. We also personalize 3D outfits on-the-fly by combining state-of-the-art image segmentation, quilting, and in-painting techniques. Rendering the model on a variety of user devices across multi-resolution use-cases presents a challenge because of different compute and memory capabilities. We solve this problem by using four different 3D meshes with varying poly-counts and mapping them using geometric optimization. Further, to enable voice-based lip-sync, we use transfer learning to fine-tune state-of-the-art speech-to-text models for predicting phonemes.</p>
    </div>




    {% block content %}
    {% endblock %}

    <h2 class="exp">Results</h2>
    <table class="tg" id="metrics">
    <thead>
      <tr>
        <th class="tg-7btt">Features</th>
        <th class="tg-7btt">Space</th>
        <th class="tg-7btt">Male</th>
        <th class="tg-7btt">Female</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td class="tg-0pky">Eyes(ACC)</td>
        <td class="tg-c3ow">17</td>
        <td class="tg-c3ow">37.10</td>
        <td class="tg-c3ow">48.96</td>
      </tr>
      <tr>
        <td class="tg-0pky">Cheek Lines(ACC)</td>
        <td class="tg-c3ow">2</td>
        <td class="tg-c3ow">96.14</td>
        <td class="tg-c3ow">96.14</td>
      </tr>
      <tr>
        <td class="tg-0pky">Dimples(ACC)</td>
        <td class="tg-c3ow">2</td>
        <td class="tg-c3ow">89.30</td>
        <td class="tg-c3ow">89.30</td>
      </tr>
      <tr>
        <td class="tg-0pky">Eye Brow Contour(ACC)</td>
        <td class="tg-c3ow">28</td>
        <td class="tg-c3ow">28.26</td>
        <td class="tg-c3ow">22.85</td>
      </tr>
      <tr>
        <td class="tg-0pky">Face Chubbiness(MSE)</td>
        <td class="tg-c3ow">-</td>
        <td class="tg-c3ow">0.16</td>
        <td class="tg-c3ow">0.19</td>
      </tr>
      <tr>
        <td class="tg-0pky">Hair Length(ACC)</td>
        <td class="tg-c3ow">4</td>
        <td class="tg-c3ow">96.54</td>
        <td class="tg-c3ow">92.60</td>
      </tr>
      <tr>
        <td class="tg-0pky">Hair Texture(ACC)</td>
        <td class="tg-c3ow">4</td>
        <td class="tg-c3ow">93.45</td>
        <td class="tg-c3ow">89.70</td>
      </tr>
      <tr>
        <td class="tg-0pky">Hair Symmetry(ACC)</td>
        <td class="tg-c3ow">4</td>
        <td class="tg-c3ow">91.62</td>
        <td class="tg-c3ow">82.50</td>
      </tr>
      <tr>
        <td class="tg-0pky">Hair Parting(ACC)</td>
        <td class="tg-c3ow">5</td>
        <td class="tg-c3ow">86.34</td>
        <td class="tg-c3ow">77.40</td>
      </tr>
      <tr>
        <td class="tg-0pky">Hair Forehead Coverage</td>
        <td class="tg-c3ow">6</td>
        <td class="tg-c3ow">90.28</td>
        <td class="tg-c3ow">81.96</td>
      </tr>
    </tbody>
    </table>  
    <li id="metric">Performance of Multi task learner on Evaluation Metrics for different components related to female and male</li>

    <table class="tg" id="tgSpeech">
      <thead>
        <tr>
          <th class="tg-7btt">Method</th>
          <th class="tg-7btt">PER</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td class="tg-0pky">Deep Speech 2</td>
          <td class="tg-c3ow">65.62</td>
        </tr>
        <tr>
          <td class="tg-0pky">Wav2Vec2 Base Model</td>
          <td class="tg-c3ow">55.21</td>
        </tr>
        <tr>
          <td class="tg-0pky">Proposed Model</td>
          <td class="tg-c3ow">27.34</td>
        </tr>
      </tbody>
    </table>
    <li id="speech"> Comparison of proposed Lip Synchronization method with baseline models</li>
    <h2 class="exp">Conclusion</h2>
    <p class="conclusion">Our system demonstrates the combined impact of hyper-personalization with rich capturing diversity of fashion choices on-the-fly, powered by a novel multitask learner that requires just a single image. Further, we enable a lip sync flow that is a significant improvement over existing art. Finally, the hyperpersonalization avatar can animate seamlessly while maintaining all the personalization aspects, and is portable to 4 different resolutions seamlessly. In the future experiments, we intend to focus further improving finer hyper-personalization aspects of the avatar (e.g.: facial depth features, skin textures etc.). Also, we are creating a multi-lingual lip synchronization flow that would make the avatar truly representative of diverse human languages and dialects. We also propose to further innovate on the multi-resolution aspects of the avatar by leveraging state of the art differentiable rendering techniques.</p>
    <h2 class="exp">References</h2>
    <div class="refRow">
      <ol class="colRef">
        <li>Alejandro Acero. Acoustical and environmental robustness in automatic speech recognition. 1991.</li>
        <li>Dario Amodei, Sundaram Ananthanarayanan, Rishita Anubhai, Jingliang Bai, Eric Battenberg, Carl Case, Jared Casper, Bryan Catanzaro, Qiang Cheng, Guoliang Chen, Jie Chen, Jingdong Chen, Zhijie Chen, Mike Chrzanowski, Adam Coates, Greg Diamos, Ke Ding, Niandong Du, Erich Elsen, and Zhenyao Zhu. Deep Speech 2: End-to-End Speech Recognition in English and Mandarin. 2015.</li>
        <li>Baevski, A., Zhou, Y., Mohamed, A., & Auli, M. (2020). wav2vec 2.0: A framework for self-supervised learning of speech representations. Advances in Neural Information Processing Systems, 33, 12449-12460.</li>
        <li>McAuliffe, M., Socolof, M., Mihuc, S., Wagner, M., & Sonderegger, M. (2017, August). Montreal Forced Aligner: Trainable Text-Speech Alignment Using Kaldi. In Interspeech (Vol. 2017, pp. 498-502).</li>
        <li> MediaPipe, Cross-platform, customizable ML solutions for live and streaming media, https://github.com/google/mediapipe, 2019.</li>
        <li>Yamagishi, Junichi; Veaux, Christophe; MacDonald, Kirsten. (2019). CSTR VCTK Corpus: English Multi-speaker Corpus for CSTR Voice Cloning Toolkit (version 0.92), [sound]. University of Edinburgh. The Centre for Speech Technology Research (CSTR). https://doi.org/10.7488/ds/2645.</li>
      </ol>
      <ol class="colRef" start="7">
        <li>Loper, M., Mahmood, N., Romero, J., Pons-Moll, G., & Black, M. J. (2015). SMPL: A skinned multi-person linear model. ACM transactions on graphics (TOG), 34(6), 1-16.</li>
        <li>Egger, B., Smith, W. A., Tewari, A., Wuhrer, S., Zollhoefer, M., Beeler, T., ... & Vetter, T. (2020). 3d morphable face modelsâ€”past, present, and future. ACM Transactions on Graphics (TOG), 39(5), 1-38.</li>
        <li>Roth, D., Stauffert, J. P., & Latoschik, M. E. (2019). Avatar Embodiment, Behavior Replication, and Kinematics in Virtual Reality. VR Developer Gems, 1, 321-348.</li>
        <li>Waltemate, T., Gall, D., Roth, D., Botsch, M., & Latoschik, M. E. (2018). The impact of avatar personalization and immersion on virtual body ownership, presence, and emotional response. IEEE transactions on visualization and computer graphics, 24(4), 1643-1652.</li>
        <li>Swartout, W., Artstein, R., Forbell, E., Foutz, S., Lane, H. C., Lange, B., ... & Traum, D. (2013). Virtual humans for learning. AI magazine, 34(4), 13-30.</li>
      </ol>
    </div>
    
    <!-- BootStrap 5.2.0 Beta JavaScript Bundle with Popper -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0-beta1/dist/js/bootstrap.bundle.min.js" integrity="sha384-pprn3073KE6tl6bjs2QrFaJGz5/SUsLqktiwsUTF55Jfv3qYSDhgCecCxMW52nD2" crossorigin="anonymous"></script> 
    <script src="{{url_for('static', _external = True, _scheme = 'https', filename = '/main.js')}}"></script>
</body>
</html>